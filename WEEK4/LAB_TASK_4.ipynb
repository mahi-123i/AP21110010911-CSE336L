{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "x = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
        "y = np.array([1, 3, 2, 5, 7, 8, 8, 9, 10, 12])\n",
        "\n",
        "def analytical_linear_regression(x, y):\n",
        "    n = len(x)\n",
        "    x_mean = np.mean(x)\n",
        "    y_mean = np.mean(y)\n",
        "    xy_mean = np.mean(x * y)\n",
        "    x_squared_mean = np.mean(x**2)\n",
        "\n",
        "    slope = (xy_mean - x_mean * y_mean) / (x_squared_mean - x_mean**2)\n",
        "    intercept = y_mean - slope * x_mean\n",
        "\n",
        "    y_pred = slope * x + intercept\n",
        "\n",
        "    sse = np.sum((y - y_pred)**2)\n",
        "\n",
        "    ssr = np.sum((y_pred - y_mean)**2)\n",
        "    sst = np.sum((y - y_mean)**2)\n",
        "    r_squared = ssr / sst\n",
        "\n",
        "    return slope, intercept, sse, r_squared\n",
        "\n",
        "def gradient_descent_linear_regression(x, y, learning_rate=0.01, epochs=1000, tol=1e-6):\n",
        "    n = len(x)\n",
        "    slope = 0\n",
        "    intercept = 0\n",
        "    prev_slope = 1\n",
        "    prev_intercept = 1\n",
        "    iter_count = 0\n",
        "\n",
        "    while iter_count < epochs and abs(prev_slope - slope) > tol and abs(prev_intercept - intercept) > tol:\n",
        "        prev_slope = slope\n",
        "        prev_intercept = intercept\n",
        "        y_pred = slope * x + intercept\n",
        "        slope -= (2 / n) * learning_rate * np.sum((y_pred - y) * x)\n",
        "        intercept -= (2 / n) * learning_rate * np.sum(y_pred - y)\n",
        "        iter_count += 1\n",
        "\n",
        "    sse = np.sum((y - (slope * x + intercept))**2)\n",
        "    y_mean = np.mean(y)\n",
        "    ssr = np.sum((slope * x + intercept - y_mean)**2)\n",
        "    sst = np.sum((y - y_mean)**2)\n",
        "    r_squared = ssr / sst\n",
        "\n",
        "    return slope, intercept, sse, r_squared\n",
        "\n",
        "slope_analytical, intercept_analytical, sse_analytical, r_squared_analytical = analytical_linear_regression(x, y)\n",
        "print(\"Analytical Solution:\")\n",
        "print(\"Slope:\", slope_analytical)\n",
        "print(\"Intercept:\", intercept_analytical)\n",
        "print(\"Sum of Squared Error (SSE):\", sse_analytical)\n",
        "print(\"R-squared:\", r_squared_analytical)\n",
        "slope_gradient, intercept_gradient, sse_gradient, r_squared_gradient = gradient_descent_linear_regression(x, y)\n",
        "print(\"\\nGradient Descent Solution:\")\n",
        "print(\"Slope:\", slope_gradient)\n",
        "print(\"Intercept:\", intercept_gradient)\n",
        "print(\"Sum of Squared Error (SSE):\", sse_gradient)\n",
        "print(\"R-squared:\", r_squared_gradient)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uY6WVHg8Z1XG",
        "outputId": "7e8a933f-ea90-4978-9e14-7c6805004c75"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analytical Solution:\n",
            "Slope: 1.1696969696969695\n",
            "Intercept: 1.2363636363636372\n",
            "Sum of Squared Error (SSE): 5.624242424242422\n",
            "R-squared: 0.9525380386139874\n",
            "\n",
            "Gradient Descent Solution:\n",
            "Slope: 1.170263693076768\n",
            "Intercept: 1.2328099487610318\n",
            "Sum of Squared Error (SSE): 5.624278989977716\n",
            "R-squared: 0.9534613650109194\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDUOcDF7YqnC",
        "outputId": "7ffd79b2-2f8a-4b36-99fc-a4e0d12c0ca7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficients using Analytic Formulation: [44459.72916908 41933.84939381]\n",
            "Coefficients using Full-batch Gradient Descent: [39148.47787113 43047.96802282]\n",
            "Coefficients using Stochastic Gradient Descent: [39699.61079795 43224.33606282]\n",
            "SSE and R-squared value:\n",
            "Analytic Formulation: SSE = 29272299281848.184 , R-squared = 0.4588591890384667\n",
            "Full-batch Gradient Descent: SSE = 29321631561932.883 , R-squared = 0.4579472104543938\n",
            "Stochastic Gradient Descent: SSE = 29322871000039.15 , R-squared = 0.4579242976474598\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "housing_data = pd.read_csv(\"housing.csv\")\n",
        "\n",
        "selected_attribute = 'median_income'\n",
        "X = housing_data[selected_attribute].values.reshape(-1, 1)\n",
        "y = housing_data['median_house_value'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train_with_intercept = np.c_[np.ones(X_train.shape[0]), X_train]\n",
        "X_test_with_intercept = np.c_[np.ones(X_test.shape[0]), X_test]\n",
        "\n",
        "theta_analytic = np.linalg.inv(X_train_with_intercept.T.dot(X_train_with_intercept)).dot(X_train_with_intercept.T).dot(y_train)\n",
        "print(\"Coefficients using Analytic Formulation:\", theta_analytic)\n",
        "\n",
        "def full_batch_gradient_descent(X, y, learning_rate, num_iterations):\n",
        "    theta = np.zeros(X.shape[1])\n",
        "    for _ in range(num_iterations):\n",
        "        y_pred = X.dot(theta)\n",
        "        theta -= (1/len(y)) * learning_rate * X.T.dot(y_pred - y)\n",
        "    return theta\n",
        "\n",
        "learning_rate = 0.01\n",
        "num_iterations = 1000\n",
        "theta_full_batch = full_batch_gradient_descent(X_train_with_intercept, y_train, learning_rate, num_iterations)\n",
        "print(\"Coefficients using Full-batch Gradient Descent:\", theta_full_batch)\n",
        "\n",
        "def stochastic_gradient_descent(X, y, learning_rate, num_iterations):\n",
        "    theta = np.zeros(X.shape[1])\n",
        "    for _ in range(num_iterations):\n",
        "        for i in range(len(y)):\n",
        "            rand_index = np.random.randint(0, len(y))\n",
        "            xi = X[rand_index]\n",
        "            yi = y[rand_index]\n",
        "            y_pred = np.dot(xi, theta)\n",
        "            theta -= learning_rate * xi * (y_pred - yi)\n",
        "    return theta\n",
        "\n",
        "theta_stochastic = stochastic_gradient_descent(X_train_with_intercept, y_train, learning_rate, num_iterations)\n",
        "print(\"Coefficients using Stochastic Gradient Descent:\", theta_stochastic)\n",
        "y_pred_analytic = X_test_with_intercept.dot(theta_analytic)\n",
        "y_pred_full_batch = X_test_with_intercept.dot(theta_full_batch)\n",
        "y_pred_stochastic = X_test_with_intercept.dot(theta_stochastic)\n",
        "\n",
        "SSE_analytic = np.sum((y_test - y_pred_analytic) ** 2)\n",
        "SSE_full_batch = np.sum((y_test - y_pred_full_batch) ** 2)\n",
        "SSE_stochastic = np.sum((y_test - y_pred_stochastic) ** 2)\n",
        "\n",
        "mean_y_test = np.mean(y_test)\n",
        "SST = np.sum((y_test - mean_y_test) ** 2)\n",
        "\n",
        "R_squared_analytic = 1 - (SSE_analytic / SST)\n",
        "R_squared_full_batch = 1 - (SSE_full_batch / SST)\n",
        "R_squared_stochastic = 1 - (SSE_stochastic / SST)\n",
        "\n",
        "print(\"SSE and R-squared value:\")\n",
        "print(\"Analytic Formulation: SSE =\", SSE_analytic, \", R-squared =\", R_squared_analytic)\n",
        "print(\"Full-batch Gradient Descent: SSE =\", SSE_full_batch, \", R-squared =\", R_squared_full_batch)\n",
        "print(\"Stochastic Gradient Descent: SSE =\", SSE_stochastic, \", R-squared =\", R_squared_stochastic)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_Xe4ommIdR7E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}